# Hermeto Mock

This file documents the steps followed to mock multi-architecture hermetic builds using [hermeto](https://hermetoproject.github.io/hermeto/pip/).

## Overview

### Goal
Build container images for **both x86_64 and aarch64** architectures using **hermetic builds** (no network access during container build).

### Challenges
1. **Multi-architecture support**: PyTorch has different dependencies per architecture
   - x86_64: Includes CUDA/GPU support (nvidia-* packages)
   - aarch64: CPU-only (no CUDA on ARM)
2. **Hermetic builds**: All dependencies must be pre-fetched by hermeto
3. **Rust-based Python packages**: Garak dependencies include packages with Rust code (base2048, tiktoken, etc.)
4. **Large dependency tree**: ~150-200 packages including PyTorch, transformers, etc.

### Approach
1. Create **separate requirements files** per architecture (x86_64 vs aarch64)
2. Generate **requirements-build.txt** for building Rust/C extensions
3. Use **hermeto** to pre-fetch all dependencies
4. Build containers using **only pre-fetched dependencies** (no PyPI/crates.io access)

## Creating requirements-*.txt files

### x86_64:

run the following command - 

```
podman run --rm \
  --platform linux/amd64 \
  -v "$(pwd)":/workspace \
  -w /workspace \
  registry.access.redhat.com/ubi9/python-312:latest \
  bash -c '
    pip install uv
    uv pip compile --generate-hashes --extra=remote pyproject.toml -o requirements-x86_64.txt
  '
```

This will create `requirements-x86_64.txt` for `x86_64` architecture.

### aarch64:

run the following command - 

```
podman run --rm \
  --platform linux/aarch64 \
  -v "$(pwd)":/workspace \
  -w /workspace \
  registry.access.redhat.com/ubi9/python-312:latest \
  bash -c '
    pip install uv
    uv pip compile --generate-hashes --extra=remote pyproject.toml -o requirements-aarch64.txt
  '
```

This will create `requirements-aarch64.txt` for `aarch64` (ARM) architecture.


Separate requirements are created because `torch` (`garak` dependency) has nvidia-cuda related deps for x86_64 arch (unless we specifically install cpu torch). But for ARM architectures, nvidia-cuda related stuff is not supported. Below is the diff of both the requirements files (cmd - `diff -u requirements-x86_64.txt requirements-aarch64.txt --color`) - 

```
--- requirements-x86_64.txt	2025-12-01 15:51:18
+++ requirements-aarch64.txt	2025-12-01 15:51:50
@@ -1,5 +1,5 @@
 # This file was autogenerated by uv via the following command:
-#    uv pip compile --generate-hashes --extra=remote pyproject.toml -o requirements-x86_64.txt
+#    uv pip compile --generate-hashes --extra=remote pyproject.toml -o requirements-aarch64.txt
 accelerate==1.12.0 \
     --hash=sha256:3e2091cd341423207e2f084a6654b1efcd250dc326f2a37d6dde446e07cabb11 \
     --hash=sha256:70988c352feb481887077d2ab845125024b2a137a5090d6d7a32b57d03a45df6
@@ -1875,87 +1875,6 @@
 nvdlib==0.8.3 \
     --hash=sha256:ba9df19942351353da5f3aa9ae9e106bbacd505a89d72d15c49f94d822690128
     # via avidtools
-nvidia-cublas-cu12==12.8.4.1 \
-    --hash=sha256:47e9b82132fa8d2b4944e708049229601448aaad7e6f296f630f2d1a32de35af \
-    --hash=sha256:8ac4e771d5a348c551b2a426eda6193c19aa630236b418086020df5ba9667142 \
-    --hash=sha256:b86f6dd8935884615a0683b663891d43781b819ac4f2ba2b0c9604676af346d0
-    # via
-    #   nvidia-cudnn-cu12
-    #   nvidia-cusolver-cu12
-    #   torch
-nvidia-cuda-cupti-cu12==12.8.90 \
-    --hash=sha256:4412396548808ddfed3f17a467b104ba7751e6b58678a4b840675c56d21cf7ed \
-    --hash=sha256:bb479dcdf7e6d4f8b0b01b115260399bf34154a1a2e9fe11c85c517d87efd98e \
-    --hash=sha256:ea0cb07ebda26bb9b29ba82cda34849e73c166c18162d3913575b0c9db9a6182
-    # via torch
-nvidia-cuda-nvrtc-cu12==12.8.93 \
-    --hash=sha256:7a4b6b2904850fe78e0bd179c4b655c404d4bb799ef03ddc60804247099ae909 \
-    --hash=sha256:a7756528852ef889772a84c6cd89d41dfa74667e24cca16bb31f8f061e3e9994 \
-    --hash=sha256:fc1fec1e1637854b4c0a65fb9a8346b51dd9ee69e61ebaccc82058441f15bce8
-    # via torch
-nvidia-cuda-runtime-cu12==12.8.90 \
-    --hash=sha256:52bf7bbee900262ffefe5e9d5a2a69a30d97e2bc5bb6cc866688caa976966e3d \
-    --hash=sha256:adade8dcbd0edf427b7204d480d6066d33902cab2a4707dcfc48a2d0fd44ab90 \
-    --hash=sha256:c0c6027f01505bfed6c3b21ec546f69c687689aad5f1a377554bc6ca4aa993a8
-    # via torch
-nvidia-cudnn-cu12==9.10.2.21 \
-    --hash=sha256:949452be657fa16687d0930933f032835951ef0892b37d2d53824d1a84dc97a8 \
-    --hash=sha256:c6288de7d63e6cf62988f0923f96dc339cea362decb1bf5b3141883392a7d65e \
-    --hash=sha256:c9132cc3f8958447b4910a1720036d9eff5928cc3179b0a51fb6d167c6cc87d8
-    # via torch
-nvidia-cufft-cu12==11.3.3.83 \
-    --hash=sha256:4d2dd21ec0b88cf61b62e6b43564355e5222e4a3fb394cac0db101f2dd0d4f74 \
-    --hash=sha256:7a64a98ef2a7c47f905aaf8931b69a3a43f27c55530c698bb2ed7c75c0b42cb7 \
-    --hash=sha256:848ef7224d6305cdb2a4df928759dca7b1201874787083b6e7550dd6765ce69a
-    # via torch
-nvidia-cufile-cu12==1.13.1.3 \
-    --hash=sha256:1d069003be650e131b21c932ec3d8969c1715379251f8d23a1860554b1cb24fc \
-    --hash=sha256:4beb6d4cce47c1a0f1013d72e02b0994730359e17801d395bdcbf20cfb3bb00a
-    # via torch
-nvidia-curand-cu12==10.3.9.90 \
-    --hash=sha256:b32331d4f4df5d6eefa0554c565b626c7216f87a06a4f56fab27c3b68a830ec9 \
-    --hash=sha256:dfab99248034673b779bc6decafdc3404a8a6f502462201f2f31f11354204acd \
-    --hash=sha256:f149a8ca457277da854f89cf282d6ef43176861926c7ac85b2a0fbd237c587ec
-    # via torch
-nvidia-cusolver-cu12==11.7.3.90 \
-    --hash=sha256:4376c11ad263152bd50ea295c05370360776f8c3427b30991df774f9fb26c450 \
-    --hash=sha256:4a550db115fcabc4d495eb7d39ac8b58d4ab5d8e63274d3754df1c0ad6a22d34 \
-    --hash=sha256:db9ed69dbef9715071232caa9b69c52ac7de3a95773c2db65bdba85916e4e5c0
-    # via torch
-nvidia-cusparse-cu12==12.5.8.93 \
-    --hash=sha256:1ec05d76bbbd8b61b06a80e1eaf8cf4959c3d4ce8e711b65ebd0443bb0ebb13b \
-    --hash=sha256:9a33604331cb2cac199f2e7f5104dfbb8a5a898c367a53dfda9ff2acb6b6b4dd \
-    --hash=sha256:9b6c161cb130be1a07a27ea6923df8141f3c295852f4b260c65f18f3e0a091dc
-    # via
-    #   nvidia-cusolver-cu12
-    #   torch
-nvidia-cusparselt-cu12==0.7.1 \
-    --hash=sha256:8878dce784d0fac90131b6817b607e803c36e629ba34dc5b433471382196b6a5 \
-    --hash=sha256:f1bb701d6b930d5a7cea44c19ceb973311500847f81b634d802b7b539dc55623 \
-    --hash=sha256:f67fbb5831940ec829c9117b7f33807db9f9678dc2a617fbe781cac17b4e1075
-    # via torch
-nvidia-nccl-cu12==2.27.5 \
-    --hash=sha256:31432ad4d1fb1004eb0c56203dc9bc2178a1ba69d1d9e02d64a6938ab5e40e7a \
-    --hash=sha256:ad730cf15cb5d25fe849c6e6ca9eb5b76db16a80f13f425ac68d8e2e55624457
-    # via torch
-nvidia-nvjitlink-cu12==12.8.93 \
-    --hash=sha256:81ff63371a7ebd6e6451970684f916be2eab07321b73c9d244dc2b4da7f73b88 \
-    --hash=sha256:adccd7161ace7261e01bb91e44e88da350895c270d23f744f0820c818b7229e7 \
-    --hash=sha256:bd93fbeeee850917903583587f4fc3a4eafa022e34572251368238ab5e6bd67f
-    # via
-    #   nvidia-cufft-cu12
-    #   nvidia-cusolver-cu12
-    #   nvidia-cusparse-cu12
-    #   torch
-nvidia-nvshmem-cu12==3.3.20 \
-    --hash=sha256:0b0b960da3842212758e4fa4696b94f129090b30e5122fea3c5345916545cff0 \
-    --hash=sha256:d00f26d3f9b2e3c3065be895e3059d6479ea5c638a3f38c9fec49b1b9dd7c1e5
-    # via torch
-nvidia-nvtx-cu12==12.8.90 \
-    --hash=sha256:5b17e2001cc0d751a5bc2c6ec6d26ad95913324a4adb86788c944f8ce9ba441f \
-    --hash=sha256:619c8304aedc69f02ea82dd244541a83c3d9d40993381b3b590f1adaed3db41e \
-    --hash=sha256:d7ad891da111ebafbf7e015d34879f7112832fc239ff0d7d776b6cb685274615
-    # via torch
 nvidia-riva-client==2.16.0 \
     --hash=sha256:99ef37b8f487d75a70c053736848221e09b728e5c910fb476333d375bd4347a3
     # via garak
@@ -3571,22 +3490,6 @@
     --hash=sha256:c77d353a4851b1880191603d36acb313411d3577f6e2897814f333841f7003f4 \
     --hash=sha256:df4945029aaddd7c09eec5cad851f30662f8bd1746721b34cc031d70c65afebc
     # via garak
-triton==3.5.1 \
-    --hash=sha256:02c770856f5e407d24d28ddc66e33cf026e6f4d360dcb8b2fabe6ea1fc758621 \
-    --hash=sha256:0b4d2c70127fca6a23e247f9348b8adde979d2e7a20391bfbabaac6aebc7e6a8 \
-    --hash=sha256:275a045b6ed670dd1bd005c3e6c2d61846c74c66f4512d6f33cc027b11de8fd4 \
-    --hash=sha256:56765ffe12c554cd560698398b8a268db1f616c120007bfd8829d27139abd24a \
-    --hash=sha256:5fc53d849f879911ea13f4a877243afc513187bc7ee92d1f2c0f1ba3169e3c94 \
-    --hash=sha256:61413522a48add32302353fdbaaf92daaaab06f6b5e3229940d21b5207f47579 \
-    --hash=sha256:8932391d7f93698dfe5bc9bead77c47a24f97329e9f20c10786bb230a9083f56 \
-    --hash=sha256:bac7f7d959ad0f48c0e97d6643a1cc0fd5786fe61cb1f83b537c6b2d54776478 \
-    --hash=sha256:d0637b1efb1db599a8e9dc960d53ab6e4637db7d4ab6630a0974705d77b14b60 \
-    --hash=sha256:d2c6b915a03888ab931a9fd3e55ba36785e1fe70cbea0b40c6ef93b20fc85232 \
-    --hash=sha256:da47169e30a779bade679ce78df4810fca6d78a955843d2ddb11f226adc517dc \
-    --hash=sha256:f3f4346b6ebbd4fad18773f5ba839114f4826037c9f2f34e0148894cd5dd3dba \
-    --hash=sha256:f617aa7925f9ea9968ec2e1adaf93e87864ff51549c8f04ce658f29bbdb71e2d \
-    --hash=sha256:f63e34dcb32d7bd3a1d0195f60f30d2aee8b08a69a0424189b71017e23dfc3d2
-    # via torch
 typing-extensions==4.15.0 \
     --hash=sha256:0cea48d173cc12fa28ecabc3b837ea3cf6f38c6d1136f85cbaaf598984861466 \
     --hash=sha256:f0fa19c6845758ab08074a0cfa8b7aecb71c999ca73d62883bc25cc018c4e548
```

As expected, the diff is only the extra cuda related stuff from x86_64 requirements file (lines started with `-`).


## Creating `requiements-build.txt`

Since `requirements-x86_64.txt` is the superset, I use it to create build requirements - 

command used - `pybuild-deps compile --generate-hashes -o requirements-build.txt requirements-x86_64.txt`

For some packages, PyPI doesn't have source code because of which pybuild-deps throws error like - `PyPI doesn't have the source code for package <pkg>==<version>`.

Unfortunately, I had to manually comment out the packages (in `requirements-x86_64.txt`) for which source code can't be found and continue creating the `requirements-build.txt`. Below are the packages that this error occured - 

- nemollm==0.3.5
- nvdlib==0.8.3
- nvidia-cublas-cu12==12.8.4.1
- nvidia-cuda-cupti-cu12==12.8.90
- nvidia-cuda-nvrtc-cu12==12.8.93
- nvidia-cuda-runtime-cu12==12.8.90
- nvidia-cudnn-cu12==9.10.2.21
- nvidia-cufft-cu12==11.3.3.83
- nvidia-cufile-cu12==1.13.1.3
- nvidia-curand-cu12==10.3.9.90
- nvidia-cusolver-cu12==11.7.3.90
- nvidia-cusparse-cu12==12.5.8.93
- nvidia-cusparselt-cu12==0.7.1
- nvidia-nccl-cu12==2.27.5
- nvidia-nvjitlink-cu12==12.8.93
- nvidia-nvshmem-cu12==3.3.20
- nvidia-nvtx-cu12==12.8.90
- nvidia-riva-client==2.16.0
- torch==2.9.1
- triton==3.5.1

It would've been nice to have a flag to enable skipping of source code cannot be found. Created issue for this - [#326](https://github.com/hermetoproject/pybuild-deps/issues/326).


## pre-fetch dependencies with hermeto

### use `all` binaries

#### x86_64

run the below command -

```
> export PROJECT_DIR="$(pwd)"
> podman run --rm -v "$PROJECT_DIR:$PROJECT_DIR:z" -w "$PROJECT_DIR" ghcr.io/hermetoproject/hermeto:latest fetch-deps --output ./hermeto-output-x86_64 '{"type": "pip", "path": ".", "requirements_files": ["requirements-x86_64.txt"], "requirements_build_files": ["requirements-build.txt"], "binary": {"packages": ":all:", "arch": "x86_64", "py_version": 312}}'
```

#### aarch64

run the below command -

```
> export PROJECT_DIR="$(pwd)"
> podman run --rm -v "$PROJECT_DIR:$PROJECT_DIR:z" -w "$PROJECT_DIR" ghcr.io/hermetoproject/hermeto:latest fetch-deps --output ./hermeto-output-aarch64 '{"type": "pip", "path": ".", "requirements_files": ["requirements-aarch64.txt"], "requirements_build_files": ["requirements-build.txt"], "binary": {"packages": ":all:", "arch": "aarch64", "py_version": 312}}' 
```

## generate env variables

run the below command to generate `hermeto.env` - 

```
podman run --rm -v "$PROJECT_DIR:$PROJECT_DIR:z" -w "$PROJECT_DIR" ghcr.io/hermetoproject/hermeto:latest generate-env ./hermeto-output-x86_64 -o ./hermeto.env --for-output-dir /tmp/hermeto-output
```


here's what `hermeto.env` contains - 

```
> cat hermeto.env 
export PIP_FIND_LINKS=/tmp/hermeto-output/deps/pip
export PIP_NO_INDEX=true
```

## build the image 

### base image

Let's create a base image with necessary with necessary tools.

#### x86_64

run the following command - 

```
podman build -f Containerfile.base . --platform linux/amd64 --tag llama-stack-garak-base-x86_64:latest
```

#### aarch64

run the following command - 

```
podman build -f Containerfile.base . --platform linux/aarch64 --tag llama-stack-garak-base-aarch64:latest
```

### x86_64

With the above base image we can build the garak iamge without network as below - 

```
> export ARCH=x86_64
> podman build -f Containerfile.hermeto . --platform linux/amd64  --build-arg TARGETARCH=${ARCH} --volume "$(realpath ./hermeto-output-x86_64)":/tmp/hermeto-output:Z --volume "$(realpath ./hermeto.env)":/tmp/hermeto.env:Z  --tag llama-stack-garak-${ARCH}:hermeto-test --network none
```

### aarch64

> This step is not working, have to debug..

run the following command -

```
> export ARCH=aarch64
> podman build -f Containerfile.hermeto . --platform linux/aarch64  --build-arg TARGETARCH=${ARCH} --volume "$(realpath ./hermeto-output-aarch64)":/tmp/hermeto-output:Z --volume "$(realpath ./hermeto.env)":/tmp/hermeto.env:Z  --tag llama-stack-garak-${ARCH}:hermeto-test  --network none
```
